{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "7adf27f0",
      "metadata": {},
      "source": [
        "# AI & Data Ethics (notater) — bachelor-vennlig\n",
        "\n",
        "Dette er strukturerte notater du kan bruke direkte i bachelortekst.\n",
        "\n",
        "## Innhold\n",
        "\n",
        "- Hva er AI-etikk? (etikk vs lov)\n",
        "- AI-livssyklusen: hvor etikk kommer inn\n",
        "- Kjerneprinsipper: privacy, transparency, accountability, fairness\n",
        "- Utvidede prinsipper: safety, explainability, non-maleficence, human oversight\n",
        "- Etisk datainnsamling (proprietær/offentlig/web-skrapet)\n",
        "- Etisk modellutvikling (labeled/unlabeled, SFT, RLHF)\n",
        "- Foundation model-risiko (hallusinasjon, inkonsistens, monitoring)\n",
        "- Regulering: GDPR + EU AI Act (risikobasert)\n",
        "- Praktisk sjekkliste + “paste-ready” formuleringer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16a8be59",
      "metadata": {},
      "source": [
        "## 1) Hva er AI-etikk – og hvorfor trenger vi det?\n",
        "\n",
        "**AI-etikk** handler om å utvikle og bruke AI slik at vi **maksimerer nytte** for samfunnet og **minimerer skade**.\n",
        "\n",
        "### Etikk vs lov\n",
        "\n",
        "- **Lover**: minimumskrav (juridisk håndhevbart).\n",
        "- **Etikk**: bredere “bør”-tenkning som krever mer nyanse, spesielt når lovverket ligger bak teknologien.\n",
        "\n",
        "**Eksempel (ofte nevnt i kurs/notater): Clearview AI**\n",
        "\n",
        "- Innspilling: ansiktsgjenkjenning + innsamling av bilder/data uten samtykke → betydelig personvernsrisiko.\n",
        "- Læringspoeng: dårlig datapraksis kan gi **store bøter**, tap av tillit og strengere regulering.\n",
        "\n",
        "Mini-refleksjon:\n",
        "\n",
        "- Hvis data er offentlig tilgjengelig på nett, er det automatisk etisk/lovlig å trene modeller på det?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd380841",
      "metadata": {},
      "source": [
        "## 2) AI-livssyklusen: hvor etikk kommer inn\n",
        "\n",
        "Etikk er ikke en sjekk “til slutt”. Den påvirker hele livssyklusen:\n",
        "\n",
        "1. Data collection\n",
        "2. Data preprocessing\n",
        "3. Model training\n",
        "4. Model evaluation\n",
        "5. Deployment\n",
        "6. Monitoring & maintenance\n",
        "\n",
        "Praktisk struktur:\n",
        "\n",
        "- **Ethical Data Collection** (1–2)\n",
        "- **Ethical AI Development** (3–4)\n",
        "- **Ethical AI Deployment** (5–6)\n",
        "\n",
        "Nøkkelidé:\n",
        "\n",
        "- Etiske feil bygges ofte inn tidlig (data/design) og blir synlige først i drift.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7391bc62",
      "metadata": {},
      "source": [
        "## 3) Kjerneprinsipper (de fire store)\n",
        "\n",
        "### 3.1 Privacy (personvern)\n",
        "\n",
        "Personvern betyr at individer har kontroll på personlig informasjon og hvordan den brukes.\n",
        "\n",
        "Praktisk:\n",
        "\n",
        "- dataminimering (samle kun det du trenger)\n",
        "- anonymisering/pseudonymisering\n",
        "- tilgangsstyring + logging\n",
        "- mekanismer for retting/sletting (der relevant)\n",
        "\n",
        "### 3.2 Transparency (transparens)\n",
        "\n",
        "Transparens betyr å være tydelig på:\n",
        "\n",
        "- hvilke data som brukes\n",
        "- hva systemet gjør\n",
        "- hvilke begrensninger/risikoer som finnes\n",
        "\n",
        "Praktisk:\n",
        "\n",
        "- brukere bør vite når de snakker med AI\n",
        "- dokumenter datakilder og beslutningsgrunnlag\n",
        "\n",
        "### 3.3 Accountability (ansvarlighet)\n",
        "\n",
        "Hvem har ansvar når AI gjør noe skadelig?\n",
        "\n",
        "Praktisk:\n",
        "\n",
        "- definer roller: “model owner”, “data owner”, “risk owner”\n",
        "- audit trail: hva skjedde, når, hvorfor\n",
        "\n",
        "### 3.4 Fairness (rettferdighet)\n",
        "\n",
        "Unngå bias/diskriminering — spesielt i høy-risiko domener (jobb, helse, strafferett).\n",
        "\n",
        "Fairness må inn i:\n",
        "\n",
        "- data collection (representasjon)\n",
        "- preprocessing (rebalansering, fjerne problematiske features)\n",
        "- training (constraints/testing)\n",
        "- evaluation (fairness-metrikker i tillegg til accuracy)\n",
        "- monitoring (kontinuerlig bias-audit)\n",
        "\n",
        "Eksempel som ofte diskuteres: COMPAS (risiko i strafferett ved skjeve prediksjoner).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f568beb2",
      "metadata": {},
      "source": [
        "## 4) Utvidede prinsipper\n",
        "\n",
        "Disse brukes ofte som “operasjonalisering” i prosjekter:\n",
        "\n",
        "- **Safety**: systemet skal ikke gjøre skade eller være lett å misbruke\n",
        "- **Explainability**: beslutninger/atferd bør være forståelige nok til revisjon og feilsøking\n",
        "- **Non-maleficence** (“do no harm”): aktivt unngå skade\n",
        "- **Human oversight**: menneske i loopen ved sensitive avgjørelser\n",
        "\n",
        "Praktisk eksempel:\n",
        "\n",
        "- test systemet på sensitive scenarioer (f.eks. diskriminerende avslag)\n",
        "- bygg failsafes (stop/eskaler)\n",
        "- logg og overvåk (drift ≠ ferdig)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7612263",
      "metadata": {},
      "source": [
        "## 5) Etisk datainnsamling (proprietær, offentlig, web-skrapet)\n",
        "\n",
        "### 5.1 Hvorfor “etisk sourcing” er mer enn å finne data\n",
        "\n",
        "Det handler om:\n",
        "\n",
        "- samtykke\n",
        "- kvalitet\n",
        "- representasjon\n",
        "- lisens/ToS\n",
        "- juridiske og sosiale konsekvenser\n",
        "\n",
        "### 5.2 Proprietær data\n",
        "\n",
        "- ofte høy kvalitet og kontroll\n",
        "- men streng tilgang og sikkerhet\n",
        "- passer i domener som bank/helse\n",
        "\n",
        "Praktisk: bruk prinsipper fra CIA-triaden (Confidentiality, Integrity, Availability).\n",
        "\n",
        "### 5.3 Offentlig data\n",
        "\n",
        "- tilgjengelig, men kan være utdatert, biased eller inneholde sensitiv info\n",
        "- må verifiseres (kilde, kvalitet, bias)\n",
        "\n",
        "### 5.4 Web-skrapet data\n",
        "\n",
        "- kraftig, men etisk/juridisk krevende\n",
        "- sjekk metadata: eier, lisens, sensitivitet\n",
        "- unngå sensitive data uten anonymisering/eksplisitt samtykke\n",
        "\n",
        "### 5.5 Sjekkliste (praktisk)\n",
        "\n",
        "1. sjekk metadata (eier, lisens, restriksjoner)\n",
        "2. verifiser ToS\n",
        "3. følg GDPR/andre regler ved persondata\n",
        "4. anonymiser ved behov\n",
        "5. spør kilden hvis uklart\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dcf52f7",
      "metadata": {},
      "source": [
        "## 6) Etisk modellutvikling: labeled/unlabeled, SFT, RLHF\n",
        "\n",
        "### Labeled data\n",
        "\n",
        "Risiko:\n",
        "\n",
        "- subjektiv labeling\n",
        "- feil/manglende kvalitet\n",
        "- bias i annotasjoner\n",
        "\n",
        "Tiltak:\n",
        "\n",
        "- tydelige labeling-guidelines\n",
        "- måle inter-annotator agreement\n",
        "- audit av “edge cases”\n",
        "\n",
        "### Unlabeled data\n",
        "\n",
        "Risiko:\n",
        "\n",
        "- uklar kontekst → bias\n",
        "- sensitive data kan snike seg inn\n",
        "\n",
        "Tiltak:\n",
        "\n",
        "- kuratering + transparens om kilder\n",
        "- overvåking av output\n",
        "\n",
        "### SFT (Supervised Fine-Tuning)\n",
        "\n",
        "- nyttig for å gjøre modellen mer stabil i format/stil\n",
        "- risiko: fine-tuning-data kan introdusere eller forsterke bias\n",
        "\n",
        "### RLHF\n",
        "\n",
        "- bruker menneskelig feedback for å forme atferd\n",
        "- risiko: bias hos evaluatorer og uklare “riktige” svar\n",
        "\n",
        "Praktisk: “one-size-fits-all” fungerer sjelden → bruk strategi som matcher domene og risiko.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9944cfe0",
      "metadata": {},
      "source": [
        "## 7) Foundation models: typiske problemer\n",
        "\n",
        "Vanlige problemer i drift:\n",
        "\n",
        "- **inkonsistens** (ulike svar på samme spørsmål)\n",
        "- **hallusinasjon** (selvsikkert, men feil)\n",
        "- bias og “unsafe” output\n",
        "\n",
        "Tiltak:\n",
        "\n",
        "- bedre data/kuratering\n",
        "- RAG for sporbarhet\n",
        "- streng prompting + output constraints\n",
        "- human-in-the-loop i sensitive scenarioer\n",
        "- kontinuerlig monitoring og retraining/oppdatering\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "daad18d4",
      "metadata": {},
      "source": [
        "## 8) Regulering: GDPR + EU AI Act (risikobasert)\n",
        "\n",
        "### GDPR (EU)\n",
        "\n",
        "- informert samtykke\n",
        "- rett til innsyn/korrigering/sletting\n",
        "- sikker håndtering + varsling ved brudd\n",
        "\n",
        "### EU AI Act (risikokategorier)\n",
        "\n",
        "- **Unacceptable risk** (forbudt): sosial scoring, manipulerende AI, m.m.\n",
        "- **High risk**: jobb, utdanning, law enforcement, kritisk infrastruktur (strenge krav)\n",
        "- **Limited risk**: transparenskrav (f.eks. chatbot må opplyse at den er AI)\n",
        "- **Minimal/no risk**: lav risiko (typiske verktøy)\n",
        "\n",
        "Poeng: compliance kan koste mer, men kan gi mer tillit og bedre styring.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20cc1e20",
      "metadata": {},
      "source": [
        "## 9) Praktisk sjekkliste (du kan bruke i oppgaver)\n",
        "\n",
        "### A) Før du bygger (use-case)\n",
        "\n",
        "- hva er nytten? hvem kan skades?\n",
        "- er domenet high-risk (jobb/helse/kritisk infrastruktur)?\n",
        "\n",
        "### B) Data\n",
        "\n",
        "- samtykke + representasjon\n",
        "- metadata/lisens/ToS\n",
        "- anonymisering + tilgang\n",
        "\n",
        "### C) Modell\n",
        "\n",
        "- test fairness på grupper\n",
        "- evaluer mer enn accuracy\n",
        "- tydelig ansvar (owners)\n",
        "\n",
        "### D) Deploy & drift\n",
        "\n",
        "- monitor bias, hallusinasjon, feil\n",
        "- logg/audit trail\n",
        "- human-in-the-loop ved sensitive avgjørelser\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b126344b",
      "metadata": {},
      "source": [
        "## 10) 3 eksamens-klare formuleringer (paste-ready)\n",
        "\n",
        "1. **Etikk vs lov**\n",
        "\n",
        "“Etikk utfyller lovverket fordi lover ofte ligger bak teknologi; etiske vurderinger gir nyanserte beslutninger der regler ikke er tydelige eller ikke finnes.”\n",
        "\n",
        "2. **Etikk gjennom livssyklus**\n",
        "\n",
        "“Etisk AI krever tiltak i hele AI-livssyklusen – fra datainnsamling og preprosessering, via trening og evaluering, til deploy og kontinuerlig monitorering.”\n",
        "\n",
        "3. **Fairness ≠ bare accuracy**\n",
        "\n",
        "“Fairness må evalueres sammen med klassiske metrikker, fordi høy accuracy kan skjule skjevheter som rammer spesifikke grupper urettferdig.”\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
