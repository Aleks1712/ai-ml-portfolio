{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9c96d3d1",
      "metadata": {},
      "source": [
        "# LangGraph + RAG (agent/pipeline) — komplett mal\n",
        "\n",
        "Denne notebooken viser hvordan du kan modellere en **RAG-løsning** som en graf:\n",
        "\n",
        "**Input → PII-maskering → Retrieval (MMR) → Stuffing → LLM → Output parsing → Policy-check → Svar**\n",
        "\n",
        "Målet er å gjøre flyten:\n",
        "\n",
        "- tydelig (for rapport/arkitektur)\n",
        "- testbar\n",
        "- sporbar (metadata, kilder, tracing)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cf7bfff",
      "metadata": {},
      "source": [
        "## 1) Hvorfor LangGraph for RAG?\n",
        "\n",
        "RAG alene kan bygges som en lineær chain. LangGraph blir nyttig når du vil ha:\n",
        "\n",
        "- **routing** (skal vi gjøre retrieval eller direkte svar?)\n",
        "- **retries** (hvis retrieval ikke finner noe)\n",
        "- **guardrails** (PII/policy noder)\n",
        "- **human-in-the-loop** (godkjenning før sending)\n",
        "- **state** som holder: question, docs, sources, answer, flags\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33684a5d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# LangGraph + RAG (kode-mal)\n",
        "# NB: Template. Krever pakker (langgraph/langchain/langchain-openai + vector store).\n",
        "\n",
        "# from __future__ import annotations\n",
        "# from typing import List, TypedDict, Literal, Optional\n",
        "#\n",
        "# from langgraph.graph import StateGraph, END\n",
        "# from langchain_core.documents import Document\n",
        "#\n",
        "# # --- 1) State\n",
        "# class RAGState(TypedDict, total=False):\n",
        "#     question: str\n",
        "#     masked_question: str\n",
        "#     retrieved_docs: List[Document]\n",
        "#     context: str\n",
        "#     answer: str\n",
        "#     sources: List[str]\n",
        "#     policy_flags: List[str]\n",
        "#\n",
        "# # --- 2) Nodes\n",
        "# def mask_pii(state: RAGState) -> RAGState:\n",
        "#     # TODO: implementer ordentlig PII-maskering (regex/spacy)\n",
        "#     q = state[\"question\"]\n",
        "#     masked = q.replace(\"@\", \"[at]\")\n",
        "#     return {\"masked_question\": masked}\n",
        "#\n",
        "# def retrieve(state: RAGState) -> RAGState:\n",
        "#     # TODO: koble på din vectordb.as_retriever(search_type=\"mmr\")\n",
        "#     # docs = retriever.invoke(state[\"masked_question\"])\n",
        "#     docs: List[Document] = []\n",
        "#     return {\"retrieved_docs\": docs}\n",
        "#\n",
        "# def stuff_context(state: RAGState) -> RAGState:\n",
        "#     docs = state.get(\"retrieved_docs\", [])\n",
        "#     def title(d: Document) -> str:\n",
        "#         return d.metadata.get(\"title\") or d.metadata.get(\"source\") or \"unknown\"\n",
        "#\n",
        "#     ctx_lines = []\n",
        "#     sources = []\n",
        "#     for d in docs:\n",
        "#         sources.append(title(d))\n",
        "#         ctx_lines.append(f\"[{title(d)}] {d.page_content}\")\n",
        "#\n",
        "#     return {\n",
        "#         \"context\": \"\\n\\n\".join(ctx_lines),\n",
        "#         \"sources\": sources,\n",
        "#     }\n",
        "#\n",
        "# def generate(state: RAGState) -> RAGState:\n",
        "#     # TODO: kall LLM (ChatOpenAI) med prompt som bruker {context}\n",
        "#     # return {\"answer\": answer}\n",
        "#     return {\"answer\": \"Answer stub (would be LLM output)\"}\n",
        "#\n",
        "# def policy_check(state: RAGState) -> RAGState:\n",
        "#     # TODO: sjekk for sensitive ting i output, hallucination-policy, osv.\n",
        "#     flags: List[str] = []\n",
        "#     if \"password\" in state.get(\"answer\", \"\").lower():\n",
        "#         flags.append(\"contains_sensitive_keyword\")\n",
        "#     return {\"policy_flags\": flags}\n",
        "#\n",
        "# def route_after_policy(state: RAGState) -> Literal[\"ok\", \"needs_review\"]:\n",
        "#     if state.get(\"policy_flags\"):\n",
        "#         return \"needs_review\"\n",
        "#     return \"ok\"\n",
        "#\n",
        "# def needs_review(state: RAGState) -> RAGState:\n",
        "#     # human-in-the-loop i praksis\n",
        "#     return {\"answer\": \"[REVIEW REQUIRED] \" + state.get(\"answer\", \"\")}\n",
        "#\n",
        "# # --- 3) Build graph\n",
        "# g = StateGraph(RAGState)\n",
        "# g.add_node(\"mask_pii\", mask_pii)\n",
        "# g.add_node(\"retrieve\", retrieve)\n",
        "# g.add_node(\"stuff\", stuff_context)\n",
        "# g.add_node(\"generate\", generate)\n",
        "# g.add_node(\"policy\", policy_check)\n",
        "# g.add_node(\"review\", needs_review)\n",
        "#\n",
        "# g.set_entry_point(\"mask_pii\")\n",
        "# g.add_edge(\"mask_pii\", \"retrieve\")\n",
        "# g.add_edge(\"retrieve\", \"stuff\")\n",
        "# g.add_edge(\"stuff\", \"generate\")\n",
        "# g.add_edge(\"generate\", \"policy\")\n",
        "#\n",
        "# g.add_conditional_edges(\"policy\", route_after_policy, {\n",
        "#     \"ok\": END,\n",
        "#     \"needs_review\": \"review\",\n",
        "# })\n",
        "# g.add_edge(\"review\", END)\n",
        "#\n",
        "# app = g.compile()\n",
        "#\n",
        "# # --- 4) Run\n",
        "# result = app.invoke({\"question\": \"Hva er SLA for delayed shipping?\"})\n",
        "# result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62752138",
      "metadata": {},
      "source": [
        "## 2) Hvordan du gjør det “bachelor-sterkt”\n",
        "\n",
        "- **Kilder/sporbarhet**: lagre `sources` fra metadata og legg dem i svaret\n",
        "- **Kostkontroll**: top-k, chunk_size/overlap, maks output tokens\n",
        "- **Policy**: PII-maskering før retrieval/LLM + policy-check etterpå\n",
        "- **Observability**: logg timing + tokenbruk per node (LangSmith passer fint)\n",
        "\n",
        "### Rapportsetning (paste-ready)\n",
        "\n",
        "> “We modeled the RAG workflow as a graph to make control-flow, safety checks, and state transitions explicit. This improves debuggability, reproducibility, and supports production-oriented features such as human-in-the-loop and policy enforcement.”\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
