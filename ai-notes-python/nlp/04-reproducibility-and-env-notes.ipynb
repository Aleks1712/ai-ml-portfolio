{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "958525d0",
      "metadata": {},
      "source": [
        "# Miljø (conda/venv) = reproducerbar forskning (kritisk i bachelor)\n",
        "\n",
        "Disse notatene forklarer *hvorfor* miljø og versjoner betyr mye, spesielt i LLM/NLP-sikkerhet (backdoors/defenses).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6976c6c0",
      "metadata": {},
      "source": [
        "## 1) Hvorfor miljø er så viktig\n",
        "\n",
        "I bachelor på post-training defenses vil du ofte:\n",
        "\n",
        "- kjøre samme forsøk mange ganger\n",
        "- sammenligne før/etter defense (pruning, unlearning, filtering, clustering)\n",
        "- måle **ASR** (attack success rate) og **utility** (clean accuracy/F1)\n",
        "\n",
        "Hvis miljøet “flyter” (ulike versjoner av `torch`/`transformers`), kan du få **spøkelsesforskjeller**:\n",
        "\n",
        "- tokenisering kan endre seg\n",
        "- defaults for generation kan endre seg\n",
        "- resultatene dine kan bli vanskelig å reprodusere\n",
        "\n",
        "> I backdoor-testing kan en liten versjonsendring endre trigger-effekt, og du kan feilaktig tro at en defense virker.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c3aa4cd",
      "metadata": {},
      "source": [
        "## 2) Conda eksempel (ryddig)\n",
        "\n",
        "```bash\n",
        "conda create --name nlp_course_env python=3.11\n",
        "conda activate nlp_course_env\n",
        "\n",
        "# basis\n",
        "pip install ipykernel jupyterlab notebook\n",
        "python -m ipykernel install --user --name nlp_course_env --display-name \"nlp_course_env\"\n",
        "```\n",
        "\n",
        "> Du kan også bruke `venv` (som i `python-for-ai/03-setting-up-the-env.ipynb`). Poenget er isolasjon + konsistente versjoner.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "059f7a88",
      "metadata": {},
      "source": [
        "## 3) “Forklar pakkene” — med backdoor-vinkling\n",
        "\n",
        "### `transformers` + `torch`\n",
        "\n",
        "- last modell/checkpoint\n",
        "- inference med/uten trigger\n",
        "- finetune/unlearn/prune\n",
        "- mål ASR + utility\n",
        "\n",
        "### `spacy` (POS/NER)\n",
        "\n",
        "- kan brukes som observasjonsverktøy\n",
        "- kan måle “entity drift” / avvik i output\n",
        "\n",
        "### `nltk` (preprocessing + n-grams)\n",
        "\n",
        "- stopwords/tokenisering/n-grams\n",
        "- n-grams kan avsløre mistenkelige fraser i poisoning\n",
        "\n",
        "### `scikit-learn`\n",
        "\n",
        "- baselines (LogReg/SVM/TF-IDF)\n",
        "- clustering for å finne “poisoned subpopulation”\n",
        "- metrikker og CV\n",
        "\n",
        "### `pandas` + plotting\n",
        "\n",
        "- logg resultater (ASR/CACC/F1)\n",
        "- plott før/etter defense\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64364807",
      "metadata": {},
      "source": [
        "## 4) Preprocessing som kontrollvariabel (backdoor-sikkerhet)\n",
        "\n",
        "I backdoor-forskning kan preprocessing både hjelpe og ødelegge.\n",
        "\n",
        "### Lowercasing\n",
        "\n",
        "- kan fjerne case-sensitive triggere\n",
        "- kan også gjøre triggere lettere å trigge\n",
        "\n",
        "### Stopword removal\n",
        "\n",
        "- kan ødelegge triggere som er avhengige av ordkombinasjoner (n-grams)\n",
        "\n",
        "### Punctuation/regex cleaning\n",
        "\n",
        "- triggere kan være tegnsekvenser (\"@@\", \"!!!\", unicode)\n",
        "\n",
        "**Bachelor-regel:** Evaluer alltid både:\n",
        "\n",
        "- rå tekst\n",
        "- normalisert tekst\n",
        "\n",
        "…og rapporter forskjellen i ASR/utility.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
