{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a0ce0b14",
      "metadata": {},
      "source": [
        "# Tekstklassifisering, sentiment, vectorisering og topic modeling (mini-rapport)\n",
        "\n",
        "Dette er en “eksamen-klar” mini-rapport som forklarer:\n",
        "\n",
        "- sentiment (rule-based vs ML vs Transformers)\n",
        "- vectorisering (BoW vs TF-IDF)\n",
        "- klassiske modeller (LogReg, Naive Bayes, Linear SVM)\n",
        "- evaluering (accuracy vs precision/recall/F1)\n",
        "- topic modeling (LDA/LSA) + coherence\n",
        "\n",
        "+ fallgruver du allerede har identifisert (A-nivå sensor-ting).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b1315e3",
      "metadata": {},
      "source": [
        "## 1) Pipeline (hva du faktisk bygger)\n",
        "\n",
        "1. tekst + label\n",
        "2. preprocessing\n",
        "3. vectorisering (tekst → tall)\n",
        "4. modell (LogReg / NB / Linear SVM)\n",
        "5. evaluering (accuracy, precision, recall, F1)\n",
        "6. feilanalyse\n",
        "\n",
        "Dette er standard i spamfilter, support-ticket tagging, SOC-klassifisering.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8891a78f",
      "metadata": {},
      "source": [
        "## 2) Sentiment: rule-based vs transformers (hvorfor du fikk “rare” resultater)\n",
        "\n",
        "### Rule-based (TextBlob, VADER)\n",
        "\n",
        "- ordlister + regler\n",
        "- sliter med kontekst/ironi/negasjon\n",
        "\n",
        "**TextBlob vs negasjon**\n",
        "\n",
        "- “wasn’t great” kan bli feil hvis modellen overvekter “great” og ikke håndterer negasjon-scope robust.\n",
        "\n",
        "**VADER**\n",
        "\n",
        "- ofte mer intuitiv på “social text” (bedre regler for negasjon/forsterkere).\n",
        "\n",
        "### Transformers\n",
        "\n",
        "Her er datasett/labels alt:\n",
        "\n",
        "- mange standardmodeller er trent binært (POS/NEG), f.eks. SST-2\n",
        "- da kan nøytrale setninger tvinges til POS eller NEG\n",
        "\n",
        "**Eksamen-gull:**\n",
        "\n",
        "> Hvis modellen ikke har NEU-klasse, kan den ikke produsere ekte nøytral.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37f0a27e",
      "metadata": {},
      "source": [
        "## 3) Vectorisering: BoW vs TF-IDF\n",
        "\n",
        "### BoW (CountVectorizer)\n",
        "\n",
        "- teller ord\n",
        "- ignorerer rekkefølge\n",
        "\n",
        "Felle: “not good” vs “good” (uten n-grams ser den bare ord, ikke frasen).\n",
        "\n",
        "### TF-IDF\n",
        "\n",
        "- gir lav vekt til vanlige ord\n",
        "- gir høyere vekt til sjeldne/informative ord\n",
        "\n",
        "Ofte en stor forbedring for klassisk tekstklassifisering.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7c6ec37",
      "metadata": {},
      "source": [
        "## 4) Modeller (eksamenforklaring)\n",
        "\n",
        "### Logistic Regression\n",
        "\n",
        "- lineær modell som lærer en vekt per feature\n",
        "- sterk baseline med TF-IDF\n",
        "\n",
        "### Multinomial Naive Bayes\n",
        "\n",
        "- sannsynlighetsmodell, antar (naivt) uavhengige ord gitt klassen\n",
        "- ekstremt rask, ofte sterk i spam-lignende data\n",
        "\n",
        "### Linear SVM\n",
        "\n",
        "- maksimerer margin\n",
        "- ofte veldig sterk på høy-dimensjonale sparse features (TF-IDF)\n",
        "\n",
        "**Viktig detalj (du hadde helt rett):**\n",
        "\n",
        "- `SGDClassifier()` er ikke automatisk SVM\n",
        "- for “SVM-ish”: `SGDClassifier(loss=\"hinge\")` eller `LinearSVC()`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "948b45f5",
      "metadata": {},
      "source": [
        "## 5) Evaluering: accuracy vs precision/recall/F1\n",
        "\n",
        "Når testsettet er lite (f.eks. 6 setninger), blir accuracy “hoppete”.\n",
        "\n",
        "- 3/6 riktig = 0.50\n",
        "- 2/6 riktig = 0.33\n",
        "\n",
        "Derfor:\n",
        "\n",
        "- bruk mer data\n",
        "- eller k-fold cross validation\n",
        "\n",
        "### Metrikker\n",
        "\n",
        "- **precision**: av det jeg kalte positivt/spam, hvor mye var riktig?\n",
        "- **recall**: av det som faktisk var positivt/spam, hvor mye fanget jeg?\n",
        "\n",
        "Tradeoff:\n",
        "\n",
        "- spam/SOC: høy recall kan være viktig (ikke misse angrep), men kan gi flere false positives.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "282d8723",
      "metadata": {},
      "source": [
        "## 6) Topic modeling: LDA/LSA + coherence\n",
        "\n",
        "### LDA (Latent Dirichlet Allocation)\n",
        "\n",
        "- dokument = miks av topics\n",
        "- topic = miks av ord\n",
        "\n",
        "Felle i nyheter:\n",
        "\n",
        "- ord som “said”, “mr”, “would” dominerer → bruk domene-stopwords.\n",
        "\n",
        "### LSA (SVD)\n",
        "\n",
        "- lineær algebra på TF-IDF\n",
        "- kan gi “latente dimensjoner”\n",
        "\n",
        "### Coherence\n",
        "\n",
        "- velg ofte topic-antall ved “knekkpunktet” (økning flater ut)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a740c41",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Kode-mal (klassisk pipeline) — krever scikit-learn\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.metrics import classification_report\n",
        "#\n",
        "# texts = [\n",
        "#     \"This was great!\",\n",
        "#     \"This wasn't great.\",\n",
        "#     \"Terrible experience.\",\n",
        "#     \"I went to see a movie.\",\n",
        "# ]\n",
        "# labels = [1, 0, 0, 0]  # eksempel\n",
        "#\n",
        "# X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.3, random_state=7)\n",
        "#\n",
        "# vec = TfidfVectorizer(ngram_range=(1,2))\n",
        "# X_train_vec = vec.fit_transform(X_train)\n",
        "# X_test_vec = vec.transform(X_test)\n",
        "#\n",
        "# clf = LogisticRegression(max_iter=1000)\n",
        "# clf.fit(X_train_vec, y_train)\n",
        "#\n",
        "# preds = clf.predict(X_test_vec)\n",
        "# print(classification_report(y_test, preds))\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
