{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "77a89a6a",
      "metadata": {},
      "source": [
        "# Transformers: special tokens (structured notes)\n",
        "\n",
        "Bachelor-nivå notater om **special tokens**, hvorfor de finnes, og hvorfor de er sikkerhetsrelevante (backdoors/prompting).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aef6c73",
      "metadata": {},
      "source": [
        "## 1) Hva er special tokens?\n",
        "\n",
        "**Special tokens** er reserverte tokens som gir modellen **struktur, kontekst og instruksjoner**.\n",
        "\n",
        "De hjelper modellen å:\n",
        "\n",
        "- forstå start/slutt og segmenter\n",
        "- håndtere batching (padding)\n",
        "- håndtere oppgaveformat (QA, klassifisering)\n",
        "\n",
        "Uten disse blir input ofte mindre stabil og vanskeligere å tolke.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2638084",
      "metadata": {},
      "source": [
        "## 2) Viktigste tokens (praktisk)\n",
        "\n",
        "### `[CLS]` — classification token\n",
        "\n",
        "- Ligger ofte først (BERT)\n",
        "- Embedding til `[CLS]` brukes ofte som “setnings-representasjon” inn i klassifikasjonshead\n",
        "\n",
        "### `[SEP]` — separator token\n",
        "\n",
        "- Skiller segmenter (spørsmål vs kontekst)\n",
        "- Marker slutt på sekvens\n",
        "\n",
        "### `[PAD]` — padding token\n",
        "\n",
        "- Gjør sekvenser like lange i en batch\n",
        "- Må ignoreres av attention (via `attention_mask`)\n",
        "\n",
        "### `[MASK]` — masked token\n",
        "\n",
        "- Brukes i BERT-pretraining (MLM)\n",
        "- Kan også brukes i testing/ablation\n",
        "\n",
        "Andre varianter:\n",
        "\n",
        "- RoBERTa: `<s>`, `</s>`\n",
        "- GPT-varianter: ofte `<bos>`, `<eos>` (navn varierer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc718016",
      "metadata": {},
      "source": [
        "## 3) Sikkerhetsrelevans (backdoors)\n",
        "\n",
        "Hvorfor dette er relevant for bachelorprosjektet ditt:\n",
        "\n",
        "- triggere kan være **token-spesifikke**\n",
        "- triggere kan plasseres nær `[CLS]`/`[SEP]` for maksimal effekt\n",
        "- **truncation** kan fjerne kontekst men beholde trigger (eller motsatt)\n",
        "- feil tokenizer kan endre triggeren (svakere/sterkere)\n",
        "\n",
        "### Praktisk regel\n",
        "\n",
        "Evaluer ASR/CACC under:\n",
        "\n",
        "- ulike `max_length`\n",
        "- med/uten truncation\n",
        "- med/uten canonicalization/normalisering\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47be1bda",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sjekk special tokens i en tokenizer (krever transformers)\n",
        "\n",
        "# from transformers import AutoTokenizer\n",
        "# tok = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "# print(tok.special_tokens_map)\n",
        "# print(\"pad_token:\", tok.pad_token, tok.pad_token_id)\n",
        "# print(\"cls_token:\", tok.cls_token, tok.cls_token_id)\n",
        "# print(\"sep_token:\", tok.sep_token, tok.sep_token_id)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
