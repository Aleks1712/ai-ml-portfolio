{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "87080418",
      "metadata": {},
      "source": [
        "# Nevrale nettverk og NLP — korte og gode notater\n",
        "\n",
        "Dette er ryddige notater (eksamen-/bachelor-vennlige) som bygger bro fra:\n",
        "\n",
        "- nevrale nettverk (grunnidé)\n",
        "- klassiske nettverkstyper (CNN/RNN)\n",
        "- hvorfor Transformers tok over NLP\n",
        "- viktige utfordringer: språkdekning, bias, personvern\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "022a7766",
      "metadata": {},
      "source": [
        "## 1) Kunstig nevron vs biologisk nevron\n",
        "\n",
        "### Kunstig nevron (Artificial Neuron)\n",
        "\n",
        "Et kunstig nevron er en matematisk modell inspirert av hjernen.\n",
        "\n",
        "Består av:\n",
        "\n",
        "- **Inputs** (signaler inn)\n",
        "- **Weights** (hvor viktig hvert input er)\n",
        "- **Summasjon** (vektet sum)\n",
        "- **Aktivering** (om nevronet “fyrer”)\n",
        "- **Output** (signal videre)\n",
        "\n",
        "Enkelt uttrykk:\n",
        "\n",
        "\\[\n",
        "\\text{output} = \\sigma(w_1x_1 + w_2x_2 + \\dots + b)\n",
        "\\]\n",
        "\n",
        "### Biologisk nevron\n",
        "\n",
        "- **Dendritter** (mottar signaler)\n",
        "- **Cellekropp** (prosesserer)\n",
        "- **Akson** (sender)\n",
        "- **Synapser** (koblinger)\n",
        "\n",
        "**Viktig:** kunstige nevroner er sterkt forenklede.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "640f4234",
      "metadata": {},
      "source": [
        "## 2) Typer nevrale nettverk (hva brukes de til?)\n",
        "\n",
        "### CNN (Convolutional Neural Networks)\n",
        "\n",
        "Brukes ofte til:\n",
        "\n",
        "- bilder/video\n",
        "- mønster- og objektgjenkjenning\n",
        "\n",
        "Hvorfor bra:\n",
        "\n",
        "- lærer lokale mønstre (kanter, former)\n",
        "- deler vekter (effektivt)\n",
        "\n",
        "### RNN (Recurrent Neural Networks)\n",
        "\n",
        "Brukes til:\n",
        "\n",
        "- sekvenser (språk, tidsserier)\n",
        "\n",
        "Kjerneidé:\n",
        "\n",
        "- tidligere output påvirker neste steg\n",
        "\n",
        "Begrensning:\n",
        "\n",
        "- sliter med lange sekvenser → ble i praksis erstattet av LSTM/GRU og senere Transformers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456c1c3d",
      "metadata": {},
      "source": [
        "## 3) Deep learning: trening, data og maskinvare\n",
        "\n",
        "- flere lag (dypere nettverk) → mer kapasitet\n",
        "- trenger ofte mye data\n",
        "- trenger ofte GPU/TPU\n",
        "\n",
        "**Trend:** framgang i deep learning henger tett sammen med maskinvareutvikling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8656c69",
      "metadata": {},
      "source": [
        "## 4) Transformers og LLMs\n",
        "\n",
        "Transformer-arkitekturen er grunnlaget for moderne NLP.\n",
        "\n",
        "Nøkkelidéer:\n",
        "\n",
        "- **self-attention**: modellen ser på hele setningen samtidig\n",
        "- ingen rekursive løkker (raskere enn RNN)\n",
        "- skalerer godt (store modeller)\n",
        "\n",
        "### ChatGPT og LLMs\n",
        "\n",
        "LLMs er ofte:\n",
        "\n",
        "- pre-trained på store mengder tekst (bøker, artikler, websider, kode)\n",
        "- fine-tuned/instruction-tuned for bedre oppgaveløsing\n",
        "\n",
        "Bruksområder:\n",
        "\n",
        "- chatbots\n",
        "- innholdsproduksjon\n",
        "- oversettelse\n",
        "- kodeassistanse\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ca6936b",
      "metadata": {},
      "source": [
        "## 5) NLP og språkdekning\n",
        "\n",
        "- NLP krever store datamengder\n",
        "- ikke alle språk har nok data/annoteringer\n",
        "\n",
        "Konsekvens:\n",
        "\n",
        "- lav-ressurs-språk støttes ofte dårligere\n",
        "- modeller kan bli skjeve (bias mot engelsk/høy-ressurs-språk)\n",
        "\n",
        "Best practice:\n",
        "\n",
        "- les modellkort/dokumentasjon\n",
        "- sjekk språkstøtte\n",
        "- vurder finetuning eller ekstra datasett\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08e092f8",
      "metadata": {},
      "source": [
        "## 6) Fremtid + utfordringer\n",
        "\n",
        "### Fremtid\n",
        "\n",
        "- bedre språkstøtte (multilingual, lav-ressurs)\n",
        "- bedre kontekst/resonnering\n",
        "- **multimodal AI** (tekst + bilde + lyd + video)\n",
        "- mer effektivitet (lavere latency, mer sanntid)\n",
        "\n",
        "### Utfordringer\n",
        "\n",
        "- etikk og misbruk (deepfakes, manipulasjon)\n",
        "- bias/diskriminering\n",
        "- personvern (trening på sensitive data, logging av brukerinput)\n",
        "\n",
        "## Kort oppsummering\n",
        "\n",
        "- CNN → bilder/video\n",
        "- RNN → sekvenser (historisk)\n",
        "- Transformers → moderne NLP/LLMs\n",
        "- utfordringer: språkulikhet, etikk, bias, personvern\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
